# SignaLink - ASL Hand Sign Recognition
SignaLink is a final year project aimed at developing an advanced computer vision and machine learning system for the recognition of American Sign Language (ASL) hand signs. This project employs both Feedforward Neural Networks (FNN) and Convolutional Neural Networks (CNN) to achieve accurate recognition of ASL hand gestures.

# Overview
The primary objective of SignaLink is to bridge the communication gap between individuals who use ASL and those who may not understand it. By leveraging cutting-edge computer vision and machine learning techniques, SignaLink aims to accurately interpret ASL hand signs in real-time, enabling seamless communication for individuals with hearing impairments.

# Features
Real-Time Recognition: SignaLink processes video input in real-time, allowing for instant recognition of ASL hand signs.
Accuracy: The system employs FNN and CNN models trained on large datasets to ensure high accuracy in recognizing a wide range of ASL gestures.
User-Friendly Interface: SignaLink features a simple and intuitive user interface, making it accessible to users of all technical backgrounds.
Customization: Users can easily customize and extend the system to accommodate additional gestures or languages.
Installation
To install SignaLink, follow these steps:

Clone the SignaLink repository from GitHub:

git clone https://github.com/PrazolMalla/signalink.git
Install the required dependencies using pip:

pip install -r requirements.txt
Run the SignaLink application:


python main.py

# Usage
Launch the SignaLink application.
Position your hand in front of the camera.
Perform the desired ASL hand sign.
The system will recognize and display the corresponding interpretation on the screen.

#Contributing
Contributions to SignaLink are welcome! If you have suggestions for improvements or new features, please submit a pull request. For major changes, please open an issue first to discuss the proposed changes.
